{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook sets the cwd to the folder containing the notebook.\n",
    "# So, you want to add the root of the project to the sys path, so modules load correctly.\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "Mostly based on YouTube video: https://youtu.be/slbZ-SLpIgg?si=JEZA-BJsM8vEuD4b\n",
    "\n",
    "From lecture slides:\n",
    "\n",
    "* Identify input parameters and distributions based on realistic estimates\n",
    "* Sample from random distribution\n",
    "* Compute output result\n",
    "* Repeat X number of times from step 2\n",
    "* Analyze output variable, e.g. mean, std-dev, probability of success?\n",
    "* Repeat whole experiment Y times to get confidence in intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Model.\n",
    "\n",
    "Convert \"We want 2 reports by end of day\" into some kind of model, with an appropriate distribution. As per the video, we are going to model the time taken to write a report by a uniform distribution. So, time to complete the reports A and B is equiprobable between the low and high limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample is A=[1.20318001], B=[4.14157275], duration=[5.34475276]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.uniform(low=1.0, high=5.0, size=1)\n",
    "B = np.random.uniform(low=2.0, high=6.0, size=1)\n",
    "duration = A + B\n",
    "print(f\"One sample is A={A}, B={B}, duration={duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you re-reun the above cell, you will get a different number each time you run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sample from Distribution X Times, Compute Output.\n",
    "\n",
    "Depending on your programming style, you can for example\n",
    "\n",
    "* Use a for loop, to sample each number, and compute model inside loop.\n",
    "* Or use array arithmetic, which should be slightly faster.\n",
    "* (or some other programming style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable controls the number of samples.\n",
    "sims = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loop: mean=7.006858796296506, std_dev=1.6331296049564739\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Using for loop. Slow, but might be easier to follow.\n",
    "duration_samples = []\n",
    "for i in range(0, sims):\n",
    "    A_sample = np.random.uniform(low=1.0, high=5.0, size=1)\n",
    "    B_sample = np.random.uniform(low=2.0, high=6.0, size=1)\n",
    "    duration_sample = A_sample + B_sample\n",
    "    duration_samples.append(duration_sample)\n",
    "\n",
    "print(f\"Using loop: mean={np.mean(duration_samples)}, std_dev={np.std(duration_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using arrays: mean=7.003426575973205, std_dev=1.6323965084354124\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Using arrays. Faster, but depending on the complexity of model, may be confusing.\n",
    "A_samples = np.random.uniform(low=1.0, high=5.0, size=sims)\n",
    "B_samples = np.random.uniform(low=2.0, high=6.0, size=sims)\n",
    "duration_samples = A_samples + B_samples\n",
    "print(f\"Using arrays: mean={np.mean(duration_samples)}, std_dev={np.std(duration_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Output.\n",
    "\n",
    "This does depend on the specific problem you are studying. You could compute \n",
    "\n",
    "* some summary statistics, e,g. mean, standard deviation of total time taken.\n",
    "* probability of total time being too much (in this case, being late for the party. i.e. total time > 9 hours.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of going over 9 hours:0.12569\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 1.5))\n",
    "plt.hist(duration_samples, density=True)\n",
    "plt.axvline(9, color='r')\n",
    "plt.show()\n",
    "print(f\"Probability of going over 9 hours:{(duration_samples > 9).sum() / sims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Limits.\n",
    "\n",
    "Imagine the scenario above was done with only 1, 2, or say 10 samples for the length of each report? Would it be a good thing to reply on the probability derived. It may be the case that the small number of samples, say 1, 2, or 10, gave exactly the right answer. But it may also be the case that we just got lucky/unlucky with the data, and we predict say 12.5 %, when in reality the unknown true value is different. What we want is a measure of certainty or \"confidence\" in the prediction. We want to be able to say, \"The expected total time is X, and I'm Y (say 95%) confident that my estimate lies within a range A-B\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals by Empirical Rule\n",
    "\n",
    "While this is simple, it is in general wrong. If we don't actually know the output distribution, it's technically wrong to assume it is Gaussian. In the general case, we would have to model the whole system and compute the mean and variance based on combining all the random variables together correctly. If we could do this, we would not need Monte Carlo simulation in the first place. Note however that it may, in simple cases like this, still produce convincing numbers. See the \"Confidence Intervals by Simulation\" method, which is data-driven, and makes no assumptions on the distributions, or independence of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total time is 7.0, and I'm 95% confident that the total time will lie within 3.8 and 10.2 hours.\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Assuming normally distributed output value (duration of time in this case). Use \"Empirical Rule\"\n",
    "\n",
    "# i.e. You hard code the rule from standard lookup tables:\n",
    "# 68% of data within 1.0 std dev.\n",
    "# 95% of data within 1.96 std dev.\n",
    "# 99.7% of data within 3 std dev.\n",
    "\n",
    "mean_of_total_times = np.mean(duration_samples)\n",
    "std_dev_of_total_times = np.std(duration_samples)\n",
    "low = np.round(mean_of_total_times - 1.96 * std_dev_of_total_times, 2)\n",
    "high = np.round(mean_of_total_times + 1.96 * std_dev_of_total_times, 2)\n",
    "\n",
    "print(f\"Expected total time is {np.round(mean_of_total_times,2)}, and I'm 95% confident that the total time will lie within {low} and {high} hours.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals by Simulation\n",
    "\n",
    "A simple way to compute 95% confidence intervals is to simply take the central 95% of the data. This makes no assumptions about the output distribution, or the independence of contributory random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total time is 7.0, and I'm 95% confident that the total time will lie within 3.9 and 10.11 hours.\n"
     ]
    }
   ],
   "source": [
    "low = np.round(np.percentile(duration_samples, 2.5), 2)\n",
    "high = np.round(np.percentile(duration_samples, 97.5), 2)\n",
    "mean_of_means = np.round(np.mean(duration_samples), 2)\n",
    "print(f\"Expected total time is {mean_of_means}, and I'm 95% confident that the total time will lie within {low} and {high} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphy0026",
   "language": "python",
   "name": "mphy0026"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
